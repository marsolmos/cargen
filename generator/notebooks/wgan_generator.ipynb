{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a wgan for generating handwritten digits\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc898e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "base_dir = \"D:/Data Warehouse/thecarconnection/pictures\" # Base directory\n",
    "categories = [item for item in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, item))] # Category that we want to use for image generation\n",
    "categories.remove(\"other\") # Don't generate images from category \"other\"\n",
    "categories.remove(\"unknown\") # Don't generate images from category \"unknown\"\n",
    "IMG_WIDTH = 56 # Target width of images when being loaded (in pixels)\n",
    "IMG_HEIGHT = 56 # Target height of images when being loaded (in pixels)\n",
    "lr = 0.000005 # Learning rate for critic and generator optimizers\n",
    "\n",
    "# define all grid search parameters\n",
    "all_latent_dim = [10, 20] # Size of the latent space\n",
    "all_n_epochs = [50] # Number of training epochs\n",
    "all_n_batch = [2, 4, 8, 16] # Size of training batches\n",
    "all_n_critic = [1, 2, 3, 4, 5] # Number of times that the critic updates per each update of generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GPU usage for training\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df190238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "    # set clip value when initialized\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    # clip model weights to hypercube\n",
    "    def __call__(self, weights):\n",
    "        return backend.clip(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "    # get the config\n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8010fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone critic model\n",
    "def define_critic(in_shape=(28,28,1), lr=0.00005):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = ClipConstraint(0.01)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    # # downsample to 112x112\n",
    "    # model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(LeakyReLU(alpha=0.2))\n",
    "    # # downsample to 56x56\n",
    "    # model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample to 28x28\n",
    "    model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample to 14x14\n",
    "    model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample to 7x7\n",
    "    model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # scoring, linear activation\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    # compile model\n",
    "    opt = RMSprop(lr=lr)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    # upsample to 14x14\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 28x28\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 56x56\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # # upsample to 112x112\n",
    "    # model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(LeakyReLU(alpha=0.2))\n",
    "    # # upsample to 224x224\n",
    "    # model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(LeakyReLU(alpha=0.2))\n",
    "    # output 112x112x1\n",
    "    model.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and critic model, for updating the generator\n",
    "def define_gan(generator, critic, lr=0.00005):\n",
    "    # make weights in the critic not trainable\n",
    "    for layer in critic.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the critic\n",
    "    model.add(critic)\n",
    "    # compile model\n",
    "    opt = RMSprop(lr=lr)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples(base_dir, category, target_size=(112, 112)):\n",
    "    '''\n",
    "    Load real samples from category directory and preprocess them in the way the network expects them\n",
    "\n",
    "    ## ARGS ##\n",
    "    base_dir[str]: path to base directory where all images are saved into one folder per category\n",
    "    categroy[str]: name of the folder with the images belonging to the category which we want to\n",
    "                   use to train the system\n",
    "    target_size[tuple]: target size if the images when being loaded.\n",
    "\n",
    "    return[np.array]: array with images loaded and preprocessed. Expected output shape will be\n",
    "                      (n_samples, width, heigth, channels). As images will be loaded as grayscale,\n",
    "                      channels will always be equal to 1.\n",
    "    '''\n",
    "    # Categories directory where to find images to generate the dataset\n",
    "    cat_dir = os.path.join(base_dir, category)\n",
    "    # Iterate for all images\n",
    "    imlist = []\n",
    "    for file in os.listdir(cat_dir):\n",
    "        img_path = os.path.join(cat_dir, file)\n",
    "        if os.path.isdir(img_path):\n",
    "            # Skip directories\n",
    "            continue\n",
    "        else:\n",
    "            # Load image into grayscale\n",
    "            im = image.load_img(img_path, target_size=target_size, color_mode=\"grayscale\")\n",
    "            # Convert image into array\n",
    "            im = image.img_to_array(im)\n",
    "            # Convert from ints to floats\n",
    "            im = im.astype('float32')\n",
    "            # Scale from [0,255] to [-1,1]\n",
    "            im = (im - 127.5) / 127.5\n",
    "            # Include into dataset\n",
    "            imlist.append(im)\n",
    "    # Generate dataset with all images in numpy.array format\n",
    "    dataset = np.array(imlist)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = dataset[ix]\n",
    "    # generate class labels, -1 for 'real'\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165123fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels with 1.0 for 'fake'\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, base_dir, n_samples=25):\n",
    "    # prepare fake examples\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(5 * 5):\n",
    "        # define subplot\n",
    "        pyplot.subplot(5, 5, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    image_name = 'generated_plot_%04d.png' % (step+1)\n",
    "    image_path = os.path.join(base_dir, 'images')\n",
    "    # create directory for images (if necessary)\n",
    "    if not os.path.isdir(image_path):\n",
    "        os.makedirs(image_path)\n",
    "    image_path = os.path.join(image_path, image_name)\n",
    "    pyplot.savefig(image_path)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    model_path = os.path.join(base_dir, 'model_saved.h5')\n",
    "    g_model.save(model_path)\n",
    "    print('>Saved: %s and %s' % (image_path, model_path))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebafcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist, base_dir):\n",
    "    # plot history\n",
    "    pyplot.plot(d1_hist, label='crit_real')\n",
    "    pyplot.plot(d2_hist, label='crit_fake')\n",
    "    pyplot.plot(g_hist, label='gen')\n",
    "    pyplot.legend()\n",
    "    save_path = os.path.join(base_dir, 'images')\n",
    "    # create directory for images (if necessary)\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    save_path = os.path.join(save_path, 'plot_line_plot_loss.png')\n",
    "    pyplot.savefig(save_path)\n",
    "    pyplot.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and critic\n",
    "def train(g_model, c_model, gan_model, dataset, category, latent_dim=50, n_epochs=100, n_batch=64, n_critic=5):\n",
    "    # base directory where to save generator model and generated images\n",
    "    model_name = \"model_\" + category +\\\n",
    "                        \"_\" + str(latent_dim) +\\\n",
    "                        \"_\" + str(n_epochs) +\\\n",
    "                        \"_\" + str(n_batch) +\\\n",
    "                        \"_\" + str(n_critic)\n",
    "    # create directory for images and model saved (if necessary)\n",
    "    base_dir = os.path.join('models', model_name)\n",
    "    if not os.path.isdir(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # lists for keeping track of loss\n",
    "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # update the critic \"n_critic times more\" than the generator\n",
    "        c1_tmp, c2_tmp = list(), list()\n",
    "        for _ in range(n_critic):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update critic model weights\n",
    "            c_loss1 = c_model.train_on_batch(X_real, y_real)\n",
    "            c1_tmp.append(c_loss1)\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update critic model weights\n",
    "            c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
    "            c2_tmp.append(c_loss2)\n",
    "        # store critic loss\n",
    "        c1_hist.append(mean(c1_tmp))\n",
    "        c2_hist.append(mean(c2_tmp))\n",
    "        # prepare points in latent space as input for the generator\n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = -ones((n_batch, 1))\n",
    "        # update the generator via the critic's error\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        g_hist.append(g_loss)\n",
    "        # summarize loss on this batch\n",
    "        print('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
    "        # evaluate the model performance every 'epoch'\n",
    "        if (i+1) % bat_per_epo == 0:\n",
    "            summarize_performance(i, g_model, latent_dim, base_dir)\n",
    "    # line plots of loss\n",
    "    plot_history(c1_hist, c2_hist, g_hist, base_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate for all posible values\n",
    "for category in categories:\n",
    "    for n_critic in all_n_critic:\n",
    "        for latent_dim in all_latent_dim:\n",
    "            for n_epochs in all_n_epochs:\n",
    "                for n_batch in all_n_batch:\n",
    "                    try:\n",
    "                        # create the critic\n",
    "                        critic = define_critic(in_shape=(IMG_WIDTH, IMG_HEIGHT, 1), lr=lr)\n",
    "                        # create the generator\n",
    "                        generator = define_generator(latent_dim)\n",
    "                        # create the gan\n",
    "                        gan_model = define_gan(generator, critic, lr=lr)\n",
    "                        # load image data\n",
    "                        dataset = load_real_samples(base_dir, category, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "                        # train model\n",
    "                        print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "                        print('TRAINING: n_crtic = {} | latent_dim = {} | n_batch = {}'.format(n_critic, latent_dim, n_batch))\n",
    "                        train(\n",
    "                            generator,\n",
    "                            critic,\n",
    "                            gan_model,\n",
    "                            dataset,\n",
    "                            category=category,\n",
    "                            latent_dim=latent_dim,\n",
    "                            n_epochs=n_epochs,\n",
    "                            n_batch=n_batch,\n",
    "                            n_critic=n_critic\n",
    "                            )\n",
    "                    except:\n",
    "                        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
