{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15642a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dead704",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'CarClass-3'\n",
    "base_dir = \"D:/Data Warehouse/thecarconnection\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de046c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with our training pictures\n",
    "train_front_dir = os.path.join(train_dir, 'front')\n",
    "train_rear_dir = os.path.join(train_dir, 'rear')\n",
    "train_front_left_dir = os.path.join(train_dir, 'front_left')\n",
    "train_front_right_dir = os.path.join(train_dir, 'front_right')\n",
    "train_left_dir = os.path.join(train_dir, 'left')\n",
    "train_right_dir = os.path.join(train_dir, 'right')\n",
    "train_rear_left_dir = os.path.join(train_dir, 'rear_left')\n",
    "train_rear_right_dir = os.path.join(train_dir, 'rear_right')\n",
    "train_other_dir = os.path.join(train_dir, 'other')\n",
    "\n",
    "# Directory with our validation pictures\n",
    "validation_front_dir = os.path.join(validation_dir, 'front')\n",
    "validation_rear_dir = os.path.join(validation_dir, 'rear')\n",
    "validation_front_left_dir = os.path.join(validation_dir, 'front_left')\n",
    "validation_front_right_dir = os.path.join(validation_dir, 'front_right')\n",
    "validation_left_dir = os.path.join(validation_dir, 'left')\n",
    "validation_right_dir = os.path.join(validation_dir, 'right')\n",
    "validation_rear_left_dir = os.path.join(validation_dir, 'rear_left')\n",
    "validation_rear_right_dir = os.path.join(validation_dir, 'rear_right')\n",
    "validation_other_dir = os.path.join(validation_dir, 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    # horizontal_flip=True,\n",
    "    )\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 32 using val_datagen generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Convolution2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Flatten feature map to a 1-dim tensor\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Create output layer with a single node and sigmoid activation\n",
    "output = layers.Dense(9, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and compile the model\n",
    "model = Model(img_input, output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d092ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSAVING MODEL!\\n')\n",
    "save_name = 'models/{}'.format(MODEL_NAME)\n",
    "model.save(save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
